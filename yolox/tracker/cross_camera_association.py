"""
Cross-Camera Association Logic for Multi-Camera Tracking
Handles complex cross-camera association scenarios and constraints
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict
import time

from .matching import cross_camera_distance, linear_assignment, embedding_distance


class CrossCameraAssociator:
    """
    Handles cross-camera association logic with various constraints and strategies
    """
    
    def __init__(self,
                 appearance_threshold: float = 0.4,\n                 temporal_threshold: int = 300,\n                 spatial_constraints: Optional[Dict] = None,\n                 min_track_length: int = 5,\n                 confidence_threshold: float = 0.5):\n        \"\"\"\n        Initialize Cross-Camera Associator\n        \n        Args:\n            appearance_threshold: Threshold for appearance similarity\n            temporal_threshold: Maximum time gap for association (frames)\n            spatial_constraints: Camera topology constraints\n            min_track_length: Minimum track length for cross-camera association\n            confidence_threshold: Minimum confidence for association\n        \"\"\"\n        self.appearance_threshold = appearance_threshold\n        self.temporal_threshold = temporal_threshold\n        self.spatial_constraints = spatial_constraints or {}\n        self.min_track_length = min_track_length\n        self.confidence_threshold = confidence_threshold\n        \n        # Association strategy\n        self.strategy = \"multi_stage\"  # \"simple\", \"multi_stage\", \"graph_based\"\n        \n        # Track association history\n        self.association_cache = {}\n        self.failed_associations = set()\n        \n        print(f\"Cross-Camera Associator initialized with strategy: {self.strategy}\")\n    \n    def associate_tracks(self, \n                        camera_tracks: Dict[str, List],\n                        global_track_manager) -> List[Tuple[str, str, int, int, float]]:\n        \"\"\"\n        Perform cross-camera association\n        \n        Args:\n            camera_tracks: Dictionary of tracks per camera\n            global_track_manager: Global track manager instance\n            \n        Returns:\n            List of association tuples: (camera_a, camera_b, track_a_id, track_b_id, confidence)\n        \"\"\"\n        if self.strategy == \"simple\":\n            return self._simple_association(camera_tracks)\n        elif self.strategy == \"multi_stage\":\n            return self._multi_stage_association(camera_tracks)\n        elif self.strategy == \"graph_based\":\n            return self._graph_based_association(camera_tracks)\n        else:\n            return self._simple_association(camera_tracks)\n    \n    def _simple_association(self, camera_tracks: Dict[str, List]) -> List[Tuple[str, str, int, int, float]]:\n        \"\"\"\n        Simple pairwise association between cameras\n        \n        Args:\n            camera_tracks: Dictionary of tracks per camera\n            \n        Returns:\n            List of associations\n        \"\"\"\n        associations = []\n        camera_list = list(camera_tracks.keys())\n        \n        # Pairwise association\n        for i in range(len(camera_list)):\n            for j in range(i + 1, len(camera_list)):\n                camera_a = camera_list[i]\n                camera_b = camera_list[j]\n                \n                tracks_a = camera_tracks[camera_a]\n                tracks_b = camera_tracks[camera_b]\n                \n                if len(tracks_a) == 0 or len(tracks_b) == 0:\n                    continue\n                \n                # Filter tracks\n                filtered_tracks_a = self._filter_tracks_for_association(tracks_a)\n                filtered_tracks_b = self._filter_tracks_for_association(tracks_b)\n                \n                if len(filtered_tracks_a) == 0 or len(filtered_tracks_b) == 0:\n                    continue\n                \n                # Compute association\n                pair_associations = self._associate_camera_pair(\n                    camera_a, camera_b, filtered_tracks_a, filtered_tracks_b\n                )\n                \n                associations.extend(pair_associations)\n        \n        return associations\n    \n    def _multi_stage_association(self, camera_tracks: Dict[str, List]) -> List[Tuple[str, str, int, int, float]]:\n        \"\"\"\n        Multi-stage association with different confidence levels\n        \n        Args:\n            camera_tracks: Dictionary of tracks per camera\n            \n        Returns:\n            List of associations\n        \"\"\"\n        associations = []\n        \n        # Stage 1: High confidence associations\n        high_conf_associations = self._simple_association(camera_tracks)\n        high_conf_filtered = [assoc for assoc in high_conf_associations \n                             if assoc[4] >= self.confidence_threshold]\n        \n        associations.extend(high_conf_filtered)\n        \n        # Stage 2: Medium confidence associations (avoid conflicts)\n        # TODO: Implement conflict resolution\n        \n        # Stage 3: Low confidence associations with additional constraints\n        # TODO: Implement additional constraints\n        \n        return associations\n    \n    def _graph_based_association(self, camera_tracks: Dict[str, List]) -> List[Tuple[str, str, int, int, float]]:\n        \"\"\"\n        Graph-based global association\n        \n        Args:\n            camera_tracks: Dictionary of tracks per camera\n            \n        Returns:\n            List of associations\n        \"\"\"\n        # TODO: Implement graph-based association\n        # For now, fall back to simple association\n        return self._simple_association(camera_tracks)\n    \n    def _associate_camera_pair(self, \n                              camera_a: str, \n                              camera_b: str,\n                              tracks_a: List, \n                              tracks_b: List) -> List[Tuple[str, str, int, int, float]]:\n        \"\"\"\n        Associate tracks between two specific cameras\n        \n        Args:\n            camera_a: First camera ID\n            camera_b: Second camera ID\n            tracks_a: Tracks from first camera\n            tracks_b: Tracks from second camera\n            \n        Returns:\n            List of associations\n        \"\"\"\n        associations = []\n        \n        # Check spatial constraints\n        if not self._check_spatial_constraints(camera_a, camera_b):\n            return associations\n        \n        # Compute appearance distance\n        cost_matrix = cross_camera_distance(\n            tracks_a, tracks_b,\n            metric='cosine',\n            max_time_gap=self.temporal_threshold\n        )\n        \n        # Apply additional constraints\n        cost_matrix = self._apply_constraints(cost_matrix, tracks_a, tracks_b)\n        \n        # Perform assignment\n        matches, unmatched_a, unmatched_b = linear_assignment(\n            cost_matrix, \n            thresh=self.appearance_threshold\n        )\n        \n        # Process matches\n        for i, j in matches:\n            if i < len(tracks_a) and j < len(tracks_b):\n                track_a = tracks_a[i]\n                track_b = tracks_b[j]\n                confidence = 1.0 - cost_matrix[i, j]\n                \n                # Additional validation\n                if self._validate_association(track_a, track_b, confidence):\n                    associations.append((\n                        camera_a, camera_b,\n                        track_a.track_id, track_b.track_id,\n                        confidence\n                    ))\n        \n        return associations\n    \n    def _filter_tracks_for_association(self, tracks: List) -> List:\n        \"\"\"\n        Filter tracks suitable for cross-camera association\n        \n        Args:\n            tracks: List of tracks\n            \n        Returns:\n            Filtered list of tracks\n        \"\"\"\n        filtered_tracks = []\n        \n        for track in tracks:\n            # Check if track is activated\n            if not track.is_activated:\n                continue\n            \n            # Check track length\n            if track.tracklet_len < self.min_track_length:\n                continue\n            \n            # Check if track has appearance features\n            if track.get_feature_for_matching() is None:\n                continue\n            \n            # Check track confidence\n            if track.score < 0.5:  # Minimum detection confidence\n                continue\n            \n            filtered_tracks.append(track)\n        \n        return filtered_tracks\n    \n    def _check_spatial_constraints(self, camera_a: str, camera_b: str) -> bool:\n        \"\"\"\n        Check if cameras can have cross-camera associations based on spatial constraints\n        \n        Args:\n            camera_a: First camera ID\n            camera_b: Second camera ID\n            \n        Returns:\n            True if association is allowed\n        \"\"\"\n        # If no spatial constraints defined, allow all associations\n        if not self.spatial_constraints:\n            return True\n        \n        # Check if cameras are connected in the spatial graph\n        camera_a_connections = self.spatial_constraints.get(camera_a, [])\n        return camera_b in camera_a_connections\n    \n    def _apply_constraints(self, cost_matrix: np.ndarray, tracks_a: List, tracks_b: List) -> np.ndarray:\n        \"\"\"\n        Apply additional constraints to cost matrix\n        \n        Args:\n            cost_matrix: Original cost matrix\n            tracks_a: Tracks from first camera\n            tracks_b: Tracks from second camera\n            \n        Returns:\n            Modified cost matrix\n        \"\"\"\n        # Temporal constraints\n        for i, track_a in enumerate(tracks_a):\n            for j, track_b in enumerate(tracks_b):\n                # Time gap constraint\n                time_gap = abs(track_a.frame_id - track_b.frame_id)\n                if time_gap > self.temporal_threshold:\n                    cost_matrix[i, j] = np.inf\n                \n                # Size similarity constraint\n                if hasattr(track_a, 'tlwh') and hasattr(track_b, 'tlwh'):\n                    size_a = track_a.tlwh[2] * track_a.tlwh[3]  # width * height\n                    size_b = track_b.tlwh[2] * track_b.tlwh[3]\n                    \n                    if size_a > 0 and size_b > 0:\n                        size_ratio = min(size_a, size_b) / max(size_a, size_b)\n                        if size_ratio < 0.5:  # Size difference too large\n                            cost_matrix[i, j] = np.inf\n        \n        return cost_matrix\n    \n    def _validate_association(self, track_a, track_b, confidence: float) -> bool:\n        \"\"\"\n        Validate a potential association\n        \n        Args:\n            track_a: First track\n            track_b: Second track\n            confidence: Association confidence\n            \n        Returns:\n            True if association is valid\n        \"\"\"\n        # Check confidence threshold\n        if confidence < self.confidence_threshold:\n            return False\n        \n        # Check if association was previously failed\n        assoc_key = (track_a.camera_id, track_a.track_id, track_b.camera_id, track_b.track_id)\n        if assoc_key in self.failed_associations:\n            return False\n        \n        # Check same camera (safety check)\n        if track_a.camera_id == track_b.camera_id:\n            return False\n        \n        return True\n    \n    def set_spatial_constraints(self, constraints: Dict[str, List[str]]):\n        \"\"\"\n        Set spatial constraints for camera associations\n        \n        Args:\n            constraints: Dictionary mapping camera ID to list of connected cameras\n        \"\"\"\n        self.spatial_constraints = constraints\n    \n    def add_failed_association(self, camera_a: str, track_a_id: int, camera_b: str, track_b_id: int):\n        \"\"\"\n        Mark an association as failed to avoid future attempts\n        \n        Args:\n            camera_a: First camera ID\n            track_a_id: First track ID\n            camera_b: Second camera ID\n            track_b_id: Second track ID\n        \"\"\"\n        assoc_key = (camera_a, track_a_id, camera_b, track_b_id)\n        self.failed_associations.add(assoc_key)\n    \n    def clear_failed_associations(self):\n        \"\"\"\n        Clear failed associations cache\n        \"\"\"\n        self.failed_associations.clear()\n    \n    def get_association_statistics(self) -> Dict:\n        \"\"\"\n        Get association statistics\n        \n        Returns:\n            Dictionary of statistics\n        \"\"\"\n        return {\n            'failed_associations_count': len(self.failed_associations),\n            'appearance_threshold': self.appearance_threshold,\n            'temporal_threshold': self.temporal_threshold,\n            'strategy': self.strategy\n        }\n    \n    def set_strategy(self, strategy: str):\n        \"\"\"\n        Set association strategy\n        \n        Args:\n            strategy: Association strategy ('simple', 'multi_stage', 'graph_based')\n        \"\"\"\n        if strategy in ['simple', 'multi_stage', 'graph_based']:\n            self.strategy = strategy\n        else:\n            raise ValueError(f\"Unknown strategy: {strategy}\")\n    \n    def reset(self):\n        \"\"\"\n        Reset association state\n        \"\"\"\n        self.association_cache.clear()\n        self.failed_associations.clear()